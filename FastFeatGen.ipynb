{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from random import shuffle\n",
    "import os, subprocess\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest1 = pd.read_csv(\"datasets/extractedFeatures_dataset.csv\", sep=',')\n",
    "dY11 = np.array(pd.read_csv(\"datasets/Positive.txt\", sep=','))\n",
    "Y11 = np.full(len(dY11)+1, 1)\n",
    "dY12 = np.array(pd.read_csv(\"datasets/Negative.txt\", sep=','))\n",
    "Y12 = np.full(len(dY12)+1, 0)\n",
    "Y1 = np.concatenate((Y11, Y12), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest2 = pd.read_csv(\"datasets/extractedFeatures_dataset2.csv\", sep=',')\n",
    "dY21 = np.array(pd.read_csv(\"datasets/Positive2.txt\", sep=','))\n",
    "Y21 = np.full(len(dY21)+1, 1)\n",
    "dY22 = np.array(pd.read_csv(\"datasets/Negative2.txt\", sep=','))\n",
    "Y22 = np.full(len(dY22)+1, 0)\n",
    "Y2 = np.concatenate((Y21, Y22), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETC (dataset1) Accuracy: 0.8448863636363636 ETC (dataset1) MCC: 0.690676352746643\n",
      "ETC (dataset1) Sensitivity: 0.8193181818181818 ETC (dataset1) Specificity: 0.8704545454545455\n"
     ]
    }
   ],
   "source": [
    "#ETCmodel_dataset1 = load(\"results/models/bestModelETC1760g1.joblib\")\n",
    "ETCfeaturesfile_dataset1 = open(\"results/models/importantfeaturesETC1760g1.txt\")\n",
    "ETCfeatures_dataset1 = ETCfeaturesfile_dataset1.readline().strip().split(\",\")[1:]\n",
    "Xtest_dataset1 = np.array(Xtest1[ETCfeatures_dataset1])\n",
    "#predictions_dataset1 = list(ETCmodel_dataset1.predict(Xtest_dataset1))\n",
    "allindices = list(range(0, len(Y1)))\n",
    "trueY1 = []\n",
    "predictions_dataset1 = []\n",
    "CV = len(Y1)\n",
    "for iterations in range(CV):\n",
    "    cvindices = []\n",
    "    for c in range(int(math.ceil(len(Y1))/CV)):\n",
    "        cvindices.append(allindices.pop(0))\n",
    "    Xtrain = Xtest_dataset1[allindices]\n",
    "    Ytrain = Y1[allindices]\n",
    "    Xtest = Xtest_dataset1[cvindices]\n",
    "    Ytest = Y1[cvindices]\n",
    "    trueY1 = trueY1 + list(Ytest)\n",
    "    clfETC = ExtraTreesClassifier(max_depth=500)\n",
    "    clfETC.fit(Xtrain, Ytrain)\n",
    "    predictions_dataset1 = predictions_dataset1 + list(clfETC.predict(Xtest))\n",
    "    allindices = allindices + cvindices\n",
    "tn_dataset1, fp_dataset1, fn_dataset1, tp_dataset1 = confusion_matrix(trueY1, predictions_dataset1).ravel()\n",
    "print('ETC (dataset1) Accuracy:', accuracy_score(trueY1, predictions_dataset1), \n",
    "      'ETC (dataset1) MCC:', matthews_corrcoef(trueY1, predictions_dataset1))\n",
    "print('ETC (dataset1) Sensitivity:', (tp_dataset1)*1.0/(tp_dataset1 + fn_dataset1), \n",
    "      'ETC (dataset1) Specificity:', (tn_dataset1)*1.0/(tn_dataset1 + fp_dataset1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETCmodel_dataset2 = load(\"results/models/bestModelETC3868g2.joblib\")\n",
    "ETCfeaturesfile_dataset2 = open(\"results/models/importantfeaturesETC3868g2.txt\")\n",
    "ETCfeatures_dataset2 = ETCfeaturesfile_dataset2.readline().strip().split(\",\")[1:]\n",
    "Xtest_dataset2 = np.array(Xtest2[ETCfeatures_dataset2])\n",
    "predictions_dataset2 = list(ETCmodel_dataset2.predict(Xtest_dataset2))\n",
    "tn_dataset2, fp_dataset2, fn_dataset2, tp_dataset2 = confusion_matrix(Y2, predictions_dataset2).ravel()\n",
    "print('ETC (dataset2) Accuracy:', accuracy_score(Y2, predictions_dataset2), \n",
    "      'ETC (dataset2) MCC:', matthews_corrcoef(Y2, predictions_dataset2))\n",
    "print('ETC (dataset2) Sensitivity:', (tp_dataset2)*1.0/(tp_dataset2 + fn_dataset2), \n",
    "      'ETC (dataset2) Specificity:', (tn_dataset2)*1.0/(tn_dataset2 + fp_dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
